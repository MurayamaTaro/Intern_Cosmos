checkpoint:
  async_saving: 'True'
  broadcast_via_filesystem: 'False'
  dcp_async_mode_enabled: 'False'
  jit:
    device: cuda
    dtype: bfloat16
    enabled: 'False'
    input_shape: null
    strict: 'True'
  keys_not_to_resume: []
  load_ema_to_reg: 'False'
  load_path: checkpoints/Cosmos-Predict1-7B-Text2World/model.pt
  load_training_state: 'False'
  lora_weight_path: posttrain_test_v1/lora_test_direct_cmd/lora_weights.pt
  only_load_scheduler_state: 'False'
  save_iter: '100'
  strict_resume: 'True'
  type: null
  verbose: 'True'
dataloader_train:
  dummy: null
dataloader_val:
  dummy: null
defaults:
- _self_
- net: null
- conditioner: add_fps_image_size_padding_mask
- tokenizer: tokenizer
- experiment: null
job:
  group: Text2World
  name: lora_test_direct_cmd
  path_local: posttrain_test_v1/lora_test_direct_cmd
  project: cosmos_diffusion
model:
  adjust_video_noise: 'False'
  conditioner:
    _target_: <class 'cosmos_predict1.diffusion.conditioner.VideoConditioner'>
    fps:
      dropout_rate: 0.0
      input_key: fps
      obj:
        _target_: <class 'cosmos_predict1.diffusion.config.base.conditioner.ReMapkey'>
        dtype: null
        output_key: fps
    image_size:
      dropout_rate: 0.0
      input_key: image_size
      obj:
        _target_: <class 'cosmos_predict1.diffusion.config.base.conditioner.ReMapkey'>
        dtype: null
        output_key: image_size
    num_frames:
      dropout_rate: 0.0
      input_key: num_frames
      obj:
        _target_: <class 'cosmos_predict1.diffusion.config.base.conditioner.ReMapkey'>
        dtype: null
        output_key: num_frames
    padding_mask:
      dropout_rate: 0.0
      input_key: padding_mask
      obj:
        _target_: <class 'cosmos_predict1.diffusion.config.base.conditioner.ReMapkey'>
        dtype: null
        output_key: padding_mask
    text:
      dropout_rate: 0.2
      input_keys:
      - t5_text_embeddings
      - t5_text_mask
      obj:
        _target_: <class 'cosmos_predict1.diffusion.conditioner.TextAttr'>
  context_parallel_size: '1'
  input_data_key: video
  input_image_key: images_1024
  latent_shape:
  - '16'
  - '16'
  - '88'
  - '160'
  net:
    _target_: <class 'cosmos_predict1.diffusion.networks.general_dit.GeneralDIT'>
    adaln_lora_dim: '256'
    affline_emb_norm: 'True'
    block_config: FA-CA-MLP
    block_x_format: THWBD
    concat_padding_mask: 'True'
    crossattn_emb_channels: '1024'
    extra_h_extrapolation_ratio: '1.0'
    extra_per_block_abs_pos_emb: 'True'
    extra_per_block_abs_pos_emb_type: learnable
    extra_t_extrapolation_ratio: '1.0'
    extra_w_extrapolation_ratio: '1.0'
    in_channels: '16'
    max_frames: '128'
    max_img_h: '240'
    max_img_w: '240'
    mlp_ratio: '4.0'
    model_channels: '4096'
    num_blocks: '28'
    num_heads: '32'
    out_channels: '16'
    patch_spatial: '2'
    patch_temporal: '1'
    pos_emb_cls: rope3d
    pos_emb_interpolation: crop
    pos_emb_learnable: 'False'
    rope_h_extrapolation_ratio: '1.0'
    rope_t_extrapolation_ratio: '2.0'
    rope_w_extrapolation_ratio: '1.0'
    use_adaln_lora: 'True'
    use_cross_attn_mask: 'False'
  num_latents_to_drop: '0'
  peft_control:
    customization_type: LoRA
    edits:
    - block_edit:
      - FA[to_q, to_v]
      - CA[to_q, to_v]
      blocks: \b(0|1|2|3|4|5|6|7|8|9|10|11|12|13|14|15|16|17|18|19|20|21|22|23|24|25|26)\b
      customization_type: LoRA
      rank: '8'
      scale: '1'
    enabled: 'True'
    rank: '8'
    scale: '1'
  precision: bfloat16
  sde: null
  sigma_data: '0.5'
  tokenizer:
    _target_: <class 'cosmos_predict1.diffusion.module.pretrained_vae.JointImageVideoSharedJITTokenizer'>
    image_vae:
      _target_: <class 'cosmos_predict1.diffusion.module.pretrained_vae.JITVAE'>
      is_bf16: 'True'
      is_image: 'False'
      latent_ch: '16'
      name: cosmos_predict1_tokenizer
    latent_ch: '16'
    name: cosmos_predict1_tokenizer
    video_vae:
      _target_: <class 'cosmos_predict1.diffusion.module.pretrained_vae.VideoJITTokenizer'>
      is_bf16: 'True'
      latent_ch: '16'
      max_dec_batch_size: '4'
      max_enc_batch_size: '8'
      name: cosmos_predict1_tokenizer
      pixel_chunk_duration: '121'
      spatial_compression_factor: '8'
      spatial_resolution: '720'
      temporal_compression_factor: '8'
  vae: null
model_obj:
  _target_: cosmos_predict1.diffusion.training.models.model_peft.PEFTVideoDiffusionModel
  config: null
model_parallel:
  _cpu_offloading_context: null
  async_tensor_model_parallel_allreduce: false
  autocast_dtype: torch.float32
  barrier_with_L1_time: true
  batch_p2p_comm: true
  batch_p2p_sync: true
  bf16: false
  context_parallel_size: 1
  cpu_offloading: false
  cpu_offloading_activations: true
  cpu_offloading_num_layers: 0
  cpu_offloading_weights: true
  cross_entropy_loss_fusion: false
  deallocate_pipeline_outputs: false
  defer_embedding_wgrad_compute: false
  deterministic_mode: false
  enable_autocast: false
  expert_model_parallel_size: 1
  expert_tensor_parallel_size: 1
  finalize_model_grads_func: null
  fp16: false
  grad_scale_func: null
  grad_sync_func: null
  gradient_accumulation_fusion: false
  hierarchical_context_parallel_sizes: null
  microbatch_group_size_per_vp_stage: 1
  moe_extended_tp: false
  no_sync_func: null
  num_microbatches_with_partial_activation_checkpoints: null
  overlap_p2p_comm: false
  overlap_p2p_comm_warmup_flush: false
  param_sync_func: null
  params_dtype: torch.float32
  perform_initialization: true
  pipeline_dtype: null
  pipeline_model_parallel_size: 1
  pipeline_model_parallel_split_rank: null
  sequence_parallel: false
  tensor_model_parallel_size: 1
  timers: null
  tp_comm_atomic_ag: false
  tp_comm_atomic_rs: false
  tp_comm_bootstrap_backend: nccl
  tp_comm_bulk_dgrad: true
  tp_comm_bulk_wgrad: true
  tp_comm_overlap: false
  tp_comm_overlap_ag: true
  tp_comm_overlap_disable_fc1: false
  tp_comm_overlap_disable_qkv: false
  tp_comm_overlap_rs: true
  tp_comm_overlap_rs_dgrad: false
  tp_comm_split_ag: true
  tp_comm_split_rs: true
  use_cpu_initialization: false
  use_ring_exchange_p2p: false
  use_te_rng_tracker: false
  variable_seq_lengths: false
  virtual_pipeline_model_parallel_size: null
  wgrad_deferral_limit: 0
optimizer:
  dummy: null
scheduler:
  dummy: null
trainer:
  callbacks:
    ema:
      _target_: <class 'cosmos_predict1.utils.callback.EMAModelCallback'>
      config: null
      trainer: null
    progress_bar:
      _target_: <class 'cosmos_predict1.utils.callback.ProgressBarCallback'>
      config: null
      trainer: null
  cudnn:
    benchmark: 'True'
    deterministic: 'False'
  ddp:
    broadcast_buffers: 'True'
    find_unused_parameters: 'False'
    static_graph: 'True'
  distributed_parallelism: ddp
  grad_accum_iter: '1'
  grad_scaler_args:
    enabled: 'False'
  logging_iter: '100'
  max_iter: '200'
  max_val_iter: null
  memory_format: torch.preserve_format
  run_validation: 'True'
  seed: '0'
  timeout_period: '999999999'
  type: <class 'cosmos_predict1.utils.trainer.Trainer'>
  validation_iter: '999999999'
